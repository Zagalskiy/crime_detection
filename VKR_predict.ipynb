{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ò–º–ø–æ—Ä—Ç –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –≤—ã–≤–æ–¥–∞ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –≤ –Ω–æ—É—Ç–±—É–∫–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.20 üöÄ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 2060, 5927MiB)\n",
      "Setup complete ‚úÖ (12 CPUs, 31.2 GB RAM, 34.4/102.2 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ `CUDA` –∏ GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Version: 12.1\n",
      "CUDA device: NVIDIA GeForce RTX 2060\n",
      "Sat May 25 12:08:02 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.171.04             Driver Version: 535.171.04   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2060        Off | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   57C    P0              27W /  80W |      8MiB /  6144MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1327      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    print('CUDA is available. Version:', torch.version.cuda)\n",
    "    print('CUDA device:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('CUDA is not available.')\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 300    # –ø–æ–¥–æ–±—Ä–∞–Ω–æ –æ–ø—ã—Ç–Ω—ã–º –ø—É—Ç—ë–º\n",
    "IMG_SIZE = 640  # —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç–∞ (416 –¥–ª—è data_folder_1)\n",
    "BATCH_SIZE = 8  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –±–∞—Ç—á–µ, –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –ø–∞–º—è—Ç–∏ GPU\n",
    "LR = 0.001      # –Ω–∞—á–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è –ø—Ä–∏ auto –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–µ)\n",
    "# –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏(SGD, Adam, AdamW, NAdam, RAdam, RMSProp, auto),\n",
    "# –≤–ª–∏—è–µ—Ç –Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç—å —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å\n",
    "OPTIMIZER = 'auto'\n",
    "MODEL_NAME = 'yolov9_d7_e300'  # –∏–º—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—É—Ç–∏ –∫ –ø–∞–ø–∫–∞–º –∏ —Ñ–∞–π–ª–∞–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞ /media/igor/WORK/ML/–î–∏–ø–ª–æ–º\n",
      "–ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É /media/igor/WORK/ML/–î–∏–ø–ª–æ–º/Crime CCTV Object Detection.v7i.yolov9\n",
      "–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ /media/igor/WORK/ML/–î–∏–ø–ª–æ–º/src/runs/detect/yolov9_d7_e300/results.csv\n",
      "–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª–∏ /media/igor/WORK/ML/–î–∏–ø–ª–æ–º/src/runs/detect/yolov9_d7_e300/weights/best.pt\n"
     ]
    }
   ],
   "source": [
    "# –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ —Ç–µ–∫—É—â–µ–π –ø–∞–ø–∫–µ /src\n",
    "# current_dir = os.path.dirname(os.path.abspath(__file__))  # –¥–ª—è .py\n",
    "current_dir = os.getcwd()  # –¥–ª—è .ipynb\n",
    "\n",
    "# –ù–∞—Ö–æ–¥–∏–º –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø–∞–ø–∫–∏ /src\n",
    "project_path = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "print(f\"–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞ {project_path}\")\n",
    "\n",
    "# –ó–∞–¥–∞—ë–º –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ –¥–∞–Ω–Ω—ã—Ö –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø–∞–ø–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞\n",
    "# data_folder_0 = os.path.join(project_path, 'theft-detection-97nip2_YOLOv9')\n",
    "# data_folder_1 = os.path.join(project_path, 'crime-detection-v8i-yolov9')\n",
    "# data_folder_2 = os.path.join(project_path, 'Crime CCTV Object Detection.v1i.yolov9')\n",
    "# data_folder_3 = os.path.join(project_path, 'Crime CCTV Object Detection.v2i.yolov9')\n",
    "# data_folder_4 = os.path.join(project_path, 'Crime CCTV Object Detection.v3i.yolov9')\n",
    "# data_folder_5 = os.path.join(project_path, 'Crime CCTV Object Detection.v5i.yolov9')\n",
    "# data_folder_6 = os.path.join(project_path, 'Crime CCTV Object Detection.v6i.yolov9')\n",
    "data_folder_7 = os.path.join(project_path, 'Crime CCTV Object Detection.v7i.yolov9')\n",
    "data_folder_8 = os.path.join(project_path, 'Crime CCTV Object Detection.v8i.yolov9')\n",
    "\n",
    "# –ó–∞–¥–∞—ë–º –ø—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É\n",
    "dataset_file = 'data.yaml'\n",
    "dataset_path = os.path.join(data_folder_7, dataset_file)\n",
    "print(f\"–ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É {data_folder_7}\")\n",
    "\n",
    "# –ó–∞–¥–∞—ë–º –ø—É—Ç—å –∫ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–µ\n",
    "model_path = os.path.join(current_dir, 'runs', 'detect', MODEL_NAME)\n",
    "\n",
    "# –°–ø–∏—Å–æ–∫  –º–æ–¥–µ–ª–µ–π\n",
    "models = [\n",
    "    MODEL_NAME,         # —Ç–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å\n",
    "    # 'yolov8n_d7_e300',\n",
    "    # 'yolov9_d7_e300',\n",
    "    # 'yolov9_d7_e161',\n",
    "    # 'yolov9_d7_e100',\n",
    "    # 'yolov9_d6_e100',\n",
    "    # 'yolov9_d5_e100',\n",
    "    # 'yolov9_d4_e100',\n",
    "    # 'yolov9_d3_50_s2',  # –¥–æ–æ–±—É—á–µ–Ω–∏–µ 'yolov9_d3_e50_aug'\n",
    "    # 'yolov9_d3_e50_aug',\n",
    "    # 'yolov9_d2_e50',\n",
    "    # 'yolov9_d1_e50_noaug',\n",
    "    # 'yolov9_d0_e100'\n",
    "]\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏\n",
    "results_file = 'results.csv'\n",
    "results_path = {key: os.path.join(current_dir, 'runs', 'detect', key, results_file) for key in models}\n",
    "print(f\"–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ {results_path[MODEL_NAME]}\")\n",
    "\n",
    "# –î–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "best_file = 'best.pt'\n",
    "output_path = os.path.join(model_path, 'weights', best_file)\n",
    "print(f\"–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª–∏ {output_path}\")\n",
    "\n",
    "# –ü—É—Ç—å –∫ –º–µ—Ç—Ä–∏–∫–∞–º –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ\n",
    "inference_path = os.path.join(model_path, 'inference')\n",
    "\n",
    "# –î–ª—è –≤—ã–≤–æ–¥–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "'''\n",
    "test_file1 = 'Theft--24-_mp4-40_jpg.rf.564b88b5933f327e08d7f7ebdf8c4cde.jpg'  # data_folder_0\n",
    "test_file2 = 'Theft--41-_mp4-3_jpg.rf.83208eab8d5ff757539623f62b191571.jpg'\n",
    "test_files = ['burg10_0118_jpg.rf.0254bd0bb0495327ea538559c0447f46.jpg',  # data_folder_1\n",
    "              'figV_5_0003_jpg.rf.41914284c4850e713aa12f4e4ba7705e.jpg',\n",
    "              'ROb16_0032_jpg.rf.1c52eb334bed44102d57ff5a3931b0ae.jpg']\n",
    "test_files = ['burg10_0118_jpg.rf.35badf5be6e43348abdb871202788cb0.jpg',  # data_folder_2 - 3\n",
    "              'figV_5_0003_jpg.rf.267c49735a53d1544ed6afac051959cc.jpg',\n",
    "              'ROb16_0032_jpg.rf.86133a8bd41af7b00e3187e3438f0410.jpg']\n",
    "test_files = ['burg10_0118_jpg.rf.dafbf0189d498ee855f2e3242b98fc22.jpg',  # data_folder_4 - 5\n",
    "              'figV_5_0003_jpg.rf.bbf327f337e28d84c2bbd87df740277a.jpg',\n",
    "              'ROb16_0032_jpg.rf.223122dde647aaf56da9531e5fd4a916.jpg']\n",
    "'''\n",
    "test_files = ['burg10_0118_jpg.rf.dafbf0189d498ee855f2e3242b98fc22.jpg',  # data_folder_6 - 7\n",
    "              'figV_5_0003_jpg.rf.8e76dd927944ee7b71037335f5552fb2.jpg',\n",
    "              'ROb41_0017_jpg.rf.708ca2b763fe3b421d6b5980b1cf25d7.jpg']\n",
    "\n",
    "test_images_path = os.path.join(project_path, data_folder_8, 'test', 'images')\n",
    "test_path3 = []\n",
    "for i in range(3):\n",
    "    test_path3.append(os.path.join(test_images_path, test_files[i]))\n",
    "\n",
    "# –î–ª—è –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è\n",
    "last_file = 'last.pt'\n",
    "resume_path = os.path.join(model_path, 'weights', last_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∫–∞ –ª—É—á—à–µ–π –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolov9_d7_e300\n",
      "YOLOv9c summary: 618 layers, 25531545 parameters, 0 gradients, 103.7 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(618, 25531545, 0, 103.69152)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_yolov9_best = YOLO(output_path)\n",
    "print(MODEL_NAME)\n",
    "model_yolov9_best.info()  # –¥–ª—è –≤—ã–≤–æ–¥–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –≤–∏–¥–µ–æ –Ω–µ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING ‚ö†Ô∏è inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "video_file = 'robbery.gif'  # robbery !\n",
    "video_path = os.path.join(current_dir, video_file)\n",
    "results = model_yolov9_best.predict(video_path, conf=0.5, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—á–∏—Å—Ç–∫–∞ –≤–∏–¥–µ–æ–∫—ç—à–∞ `PyTorch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d41536a5b5b8e265460cc2b5a796e0ad6722cc84aafa3a9ba85932aacf7955d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
